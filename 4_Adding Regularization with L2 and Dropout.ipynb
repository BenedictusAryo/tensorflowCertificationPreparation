{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Regularization with L2 and Dropout\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional to surpress warning\r\n",
    "import os\r\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers, regularizers\r\n",
    "from tensorflow.keras.datasets import cifar10\r\n",
    "\r\n",
    "# Set physical device to GPU\r\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\r\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n",
    "\r\n",
    "# Data Shape\r\n",
    "\r\n",
    "print('Data shape: ',x_train.shape)\r\n",
    "\r\n",
    "x_train = x_train.astype('float32') / 255.0\r\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model():\r\n",
    "    inputs = keras.layers.Input(shape=(32, 32, 3))\r\n",
    "    x = layers.Conv2D(\r\n",
    "            32, 3, \r\n",
    "            padding='same', \r\n",
    "            kernel_regularizer=regularizers.l2(0.01))(inputs)\r\n",
    "    x = layers.BatchNormalization()(x)\r\n",
    "    x = keras.activations.relu(x)\r\n",
    "    x = layers.MaxPool2D()(x)\r\n",
    "    x = layers.Conv2D(\r\n",
    "            64, 5, \r\n",
    "            padding='same',\r\n",
    "            kernel_regularizer=regularizers.l2(0.01))(x)\r\n",
    "    x = layers.BatchNormalization()(x)\r\n",
    "    x = keras.activations.relu(x)\r\n",
    "    x = layers.Conv2D(\r\n",
    "            128, 3,\r\n",
    "            padding='same',\r\n",
    "            kernel_regularizer=regularizers.l2(0.01))(x)\r\n",
    "    x = layers.BatchNormalization()(x)\r\n",
    "    x = keras.activations.relu(x)\r\n",
    "    x = layers.Flatten()(x)\r\n",
    "    x = layers.Dense(\r\n",
    "            64, \r\n",
    "            activation='relu',\r\n",
    "            kernel_regularizer=regularizers.l2(0.01))(x)\r\n",
    "    x = layers.Dropout(0.5)(x)\r\n",
    "    outputs = layers.Dense(10)(x)\r\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\r\n",
    "    return model\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "782/782 - 8s - loss: 3.0831 - accuracy: 0.1705\n",
      "Epoch 2/150\n",
      "782/782 - 7s - loss: 2.2188 - accuracy: 0.1939\n",
      "Epoch 3/150\n",
      "782/782 - 7s - loss: 2.0753 - accuracy: 0.2063\n",
      "Epoch 4/150\n",
      "782/782 - 7s - loss: 1.9926 - accuracy: 0.2394\n",
      "Epoch 5/150\n",
      "782/782 - 7s - loss: 1.9440 - accuracy: 0.2655\n",
      "Epoch 6/150\n",
      "782/782 - 7s - loss: 1.9110 - accuracy: 0.2799\n",
      "Epoch 7/150\n",
      "782/782 - 7s - loss: 1.8877 - accuracy: 0.2896\n",
      "Epoch 8/150\n",
      "782/782 - 7s - loss: 1.8712 - accuracy: 0.2958\n",
      "Epoch 9/150\n",
      "782/782 - 7s - loss: 1.8437 - accuracy: 0.3093\n",
      "Epoch 10/150\n",
      "782/782 - 7s - loss: 1.8355 - accuracy: 0.3138\n",
      "Epoch 11/150\n",
      "782/782 - 7s - loss: 1.8241 - accuracy: 0.3236\n",
      "Epoch 12/150\n",
      "782/782 - 7s - loss: 1.8157 - accuracy: 0.3302\n",
      "Epoch 13/150\n",
      "782/782 - 7s - loss: 1.7994 - accuracy: 0.3384\n",
      "Epoch 14/150\n",
      "782/782 - 7s - loss: 1.7892 - accuracy: 0.3434\n",
      "Epoch 15/150\n",
      "782/782 - 7s - loss: 1.7727 - accuracy: 0.3509\n",
      "Epoch 16/150\n",
      "782/782 - 7s - loss: 1.7655 - accuracy: 0.3556\n",
      "Epoch 17/150\n",
      "782/782 - 7s - loss: 1.7473 - accuracy: 0.3636\n",
      "Epoch 18/150\n",
      "782/782 - 7s - loss: 1.7384 - accuracy: 0.3694\n",
      "Epoch 19/150\n",
      "782/782 - 7s - loss: 1.7365 - accuracy: 0.3701\n",
      "Epoch 20/150\n",
      "782/782 - 7s - loss: 1.7299 - accuracy: 0.3755\n",
      "Epoch 21/150\n",
      "782/782 - 7s - loss: 1.7244 - accuracy: 0.3792\n",
      "Epoch 22/150\n",
      "782/782 - 7s - loss: 1.7143 - accuracy: 0.3815\n",
      "Epoch 23/150\n",
      "782/782 - 7s - loss: 1.7116 - accuracy: 0.3822\n",
      "Epoch 24/150\n",
      "782/782 - 7s - loss: 1.7071 - accuracy: 0.3873\n",
      "Epoch 25/150\n",
      "782/782 - 7s - loss: 1.7010 - accuracy: 0.3914\n",
      "Epoch 26/150\n",
      "782/782 - 7s - loss: 1.6944 - accuracy: 0.3910\n",
      "Epoch 27/150\n",
      "782/782 - 7s - loss: 1.7034 - accuracy: 0.3909\n",
      "Epoch 28/150\n",
      "782/782 - 7s - loss: 1.6843 - accuracy: 0.3973\n",
      "Epoch 29/150\n",
      "782/782 - 7s - loss: 1.6858 - accuracy: 0.3979\n",
      "Epoch 30/150\n",
      "782/782 - 7s - loss: 1.6882 - accuracy: 0.3938\n",
      "Epoch 31/150\n",
      "782/782 - 7s - loss: 1.6822 - accuracy: 0.4021\n",
      "Epoch 32/150\n",
      "782/782 - 7s - loss: 1.6863 - accuracy: 0.4008\n",
      "Epoch 33/150\n",
      "782/782 - 7s - loss: 1.6721 - accuracy: 0.4020\n",
      "Epoch 34/150\n",
      "782/782 - 7s - loss: 1.6811 - accuracy: 0.4019\n",
      "Epoch 35/150\n",
      "782/782 - 7s - loss: 1.6657 - accuracy: 0.4060\n",
      "Epoch 36/150\n",
      "782/782 - 7s - loss: 1.6634 - accuracy: 0.4084\n",
      "Epoch 37/150\n",
      "782/782 - 7s - loss: 1.6655 - accuracy: 0.4100\n",
      "Epoch 38/150\n",
      "782/782 - 7s - loss: 1.6676 - accuracy: 0.4098\n",
      "Epoch 39/150\n",
      "782/782 - 7s - loss: 1.6597 - accuracy: 0.4134\n",
      "Epoch 40/150\n",
      "782/782 - 7s - loss: 1.6568 - accuracy: 0.4166\n",
      "Epoch 41/150\n",
      "782/782 - 7s - loss: 1.6564 - accuracy: 0.4138\n",
      "Epoch 42/150\n",
      "782/782 - 7s - loss: 1.6557 - accuracy: 0.4152\n",
      "Epoch 43/150\n",
      "782/782 - 7s - loss: 1.6590 - accuracy: 0.4114\n",
      "Epoch 44/150\n",
      "782/782 - 7s - loss: 1.6538 - accuracy: 0.4152\n",
      "Epoch 45/150\n",
      "782/782 - 7s - loss: 1.6498 - accuracy: 0.4163\n",
      "Epoch 46/150\n",
      "782/782 - 7s - loss: 1.6485 - accuracy: 0.4208\n",
      "Epoch 47/150\n",
      "782/782 - 7s - loss: 1.6510 - accuracy: 0.4169\n",
      "Epoch 48/150\n",
      "782/782 - 7s - loss: 1.6459 - accuracy: 0.4175\n",
      "Epoch 49/150\n",
      "782/782 - 7s - loss: 1.6402 - accuracy: 0.4263\n",
      "Epoch 50/150\n",
      "782/782 - 7s - loss: 1.6445 - accuracy: 0.4212\n",
      "Epoch 51/150\n",
      "782/782 - 7s - loss: 1.6390 - accuracy: 0.4253\n",
      "Epoch 52/150\n",
      "782/782 - 7s - loss: 1.6364 - accuracy: 0.4282\n",
      "Epoch 53/150\n",
      "782/782 - 7s - loss: 1.6333 - accuracy: 0.4290\n",
      "Epoch 54/150\n",
      "782/782 - 7s - loss: 1.6349 - accuracy: 0.4286\n",
      "Epoch 55/150\n",
      "782/782 - 7s - loss: 1.6358 - accuracy: 0.4308\n",
      "Epoch 56/150\n",
      "782/782 - 7s - loss: 1.6318 - accuracy: 0.4310\n",
      "Epoch 57/150\n",
      "782/782 - 7s - loss: 1.6376 - accuracy: 0.4311\n",
      "Epoch 58/150\n",
      "782/782 - 7s - loss: 1.6288 - accuracy: 0.4322\n",
      "Epoch 59/150\n",
      "782/782 - 7s - loss: 1.6314 - accuracy: 0.4324\n",
      "Epoch 60/150\n",
      "782/782 - 7s - loss: 1.6310 - accuracy: 0.4305\n",
      "Epoch 61/150\n",
      "782/782 - 7s - loss: 1.6299 - accuracy: 0.4347\n",
      "Epoch 62/150\n",
      "782/782 - 7s - loss: 1.6267 - accuracy: 0.4359\n",
      "Epoch 63/150\n",
      "782/782 - 7s - loss: 1.6353 - accuracy: 0.4332\n",
      "Epoch 64/150\n",
      "782/782 - 7s - loss: 1.6289 - accuracy: 0.4334\n",
      "Epoch 65/150\n",
      "782/782 - 7s - loss: 1.6210 - accuracy: 0.4340\n",
      "Epoch 66/150\n",
      "782/782 - 7s - loss: 1.6182 - accuracy: 0.4355\n",
      "Epoch 67/150\n",
      "782/782 - 7s - loss: 1.6200 - accuracy: 0.4391\n",
      "Epoch 68/150\n",
      "782/782 - 7s - loss: 1.6187 - accuracy: 0.4379\n",
      "Epoch 69/150\n",
      "782/782 - 7s - loss: 1.6212 - accuracy: 0.4404\n",
      "Epoch 70/150\n",
      "782/782 - 7s - loss: 1.6264 - accuracy: 0.4379\n",
      "Epoch 71/150\n",
      "782/782 - 7s - loss: 1.6170 - accuracy: 0.4393\n",
      "Epoch 72/150\n",
      "782/782 - 7s - loss: 1.6240 - accuracy: 0.4356\n",
      "Epoch 73/150\n",
      "782/782 - 7s - loss: 1.6127 - accuracy: 0.4445\n",
      "Epoch 74/150\n",
      "782/782 - 7s - loss: 1.6229 - accuracy: 0.4388\n",
      "Epoch 75/150\n",
      "782/782 - 7s - loss: 1.6173 - accuracy: 0.4403\n",
      "Epoch 76/150\n",
      "782/782 - 7s - loss: 1.6165 - accuracy: 0.4411\n",
      "Epoch 77/150\n",
      "782/782 - 7s - loss: 1.6183 - accuracy: 0.4428\n",
      "Epoch 78/150\n",
      "782/782 - 7s - loss: 1.6231 - accuracy: 0.4373\n",
      "Epoch 79/150\n",
      "782/782 - 7s - loss: 1.6134 - accuracy: 0.4404\n",
      "Epoch 80/150\n",
      "782/782 - 7s - loss: 1.6170 - accuracy: 0.4387\n",
      "Epoch 81/150\n",
      "782/782 - 7s - loss: 1.6105 - accuracy: 0.4411\n",
      "Epoch 82/150\n",
      "782/782 - 7s - loss: 1.6063 - accuracy: 0.4433\n",
      "Epoch 83/150\n",
      "782/782 - 7s - loss: 1.6009 - accuracy: 0.4479\n",
      "Epoch 84/150\n",
      "782/782 - 7s - loss: 1.6126 - accuracy: 0.4409\n",
      "Epoch 85/150\n",
      "782/782 - 7s - loss: 1.6099 - accuracy: 0.4439\n",
      "Epoch 86/150\n",
      "782/782 - 7s - loss: 1.6109 - accuracy: 0.4455\n",
      "Epoch 87/150\n",
      "782/782 - 7s - loss: 1.6033 - accuracy: 0.4463\n",
      "Epoch 88/150\n",
      "782/782 - 7s - loss: 1.6075 - accuracy: 0.4437\n",
      "Epoch 89/150\n",
      "782/782 - 7s - loss: 1.5979 - accuracy: 0.4471\n",
      "Epoch 90/150\n",
      "782/782 - 7s - loss: 1.6110 - accuracy: 0.4419\n",
      "Epoch 91/150\n",
      "782/782 - 7s - loss: 1.6047 - accuracy: 0.4476\n",
      "Epoch 92/150\n",
      "782/782 - 7s - loss: 1.6070 - accuracy: 0.4477\n",
      "Epoch 93/150\n",
      "782/782 - 7s - loss: 1.6032 - accuracy: 0.4472\n",
      "Epoch 94/150\n",
      "782/782 - 9s - loss: 1.6056 - accuracy: 0.4466\n",
      "Epoch 95/150\n",
      "782/782 - 7s - loss: 1.6048 - accuracy: 0.4473\n",
      "Epoch 96/150\n",
      "782/782 - 7s - loss: 1.5967 - accuracy: 0.4489\n",
      "Epoch 97/150\n",
      "782/782 - 7s - loss: 1.6042 - accuracy: 0.4477\n",
      "Epoch 98/150\n",
      "782/782 - 7s - loss: 1.5938 - accuracy: 0.4513\n",
      "Epoch 99/150\n",
      "782/782 - 7s - loss: 1.6000 - accuracy: 0.4513\n",
      "Epoch 100/150\n",
      "782/782 - 7s - loss: 1.6059 - accuracy: 0.4447\n",
      "Epoch 101/150\n",
      "782/782 - 7s - loss: 1.5935 - accuracy: 0.4521\n",
      "Epoch 102/150\n",
      "782/782 - 7s - loss: 1.5976 - accuracy: 0.4488\n",
      "Epoch 103/150\n",
      "782/782 - 7s - loss: 1.5950 - accuracy: 0.4497\n",
      "Epoch 104/150\n",
      "782/782 - 7s - loss: 1.6048 - accuracy: 0.4493\n",
      "Epoch 105/150\n",
      "782/782 - 7s - loss: 1.5946 - accuracy: 0.4521\n",
      "Epoch 106/150\n",
      "782/782 - 7s - loss: 1.5954 - accuracy: 0.4504\n",
      "Epoch 107/150\n",
      "782/782 - 7s - loss: 1.5957 - accuracy: 0.4510\n",
      "Epoch 108/150\n",
      "782/782 - 7s - loss: 1.6002 - accuracy: 0.4519\n",
      "Epoch 109/150\n",
      "782/782 - 7s - loss: 1.5918 - accuracy: 0.4537\n",
      "Epoch 110/150\n",
      "782/782 - 7s - loss: 1.5954 - accuracy: 0.4530\n",
      "Epoch 111/150\n",
      "782/782 - 7s - loss: 1.5942 - accuracy: 0.4525\n",
      "Epoch 112/150\n",
      "782/782 - 7s - loss: 1.5976 - accuracy: 0.4512\n",
      "Epoch 113/150\n",
      "782/782 - 7s - loss: 1.5943 - accuracy: 0.4508\n",
      "Epoch 114/150\n",
      "782/782 - 7s - loss: 1.5917 - accuracy: 0.4541\n",
      "Epoch 115/150\n",
      "782/782 - 7s - loss: 1.5947 - accuracy: 0.4516\n",
      "Epoch 116/150\n",
      "782/782 - 7s - loss: 1.5976 - accuracy: 0.4493\n",
      "Epoch 117/150\n",
      "782/782 - 7s - loss: 1.6018 - accuracy: 0.4521\n",
      "Epoch 118/150\n",
      "782/782 - 7s - loss: 1.5923 - accuracy: 0.4507\n",
      "Epoch 119/150\n",
      "782/782 - 7s - loss: 1.5896 - accuracy: 0.4511\n",
      "Epoch 120/150\n",
      "782/782 - 7s - loss: 1.5950 - accuracy: 0.4518\n",
      "Epoch 121/150\n",
      "782/782 - 7s - loss: 1.5912 - accuracy: 0.4558\n",
      "Epoch 122/150\n",
      "782/782 - 7s - loss: 1.5932 - accuracy: 0.4534\n",
      "Epoch 123/150\n",
      "782/782 - 7s - loss: 1.6068 - accuracy: 0.4497\n",
      "Epoch 124/150\n",
      "782/782 - 7s - loss: 1.5927 - accuracy: 0.4544\n",
      "Epoch 125/150\n",
      "782/782 - 7s - loss: 1.5907 - accuracy: 0.4534\n",
      "Epoch 126/150\n",
      "782/782 - 7s - loss: 1.5812 - accuracy: 0.4604\n",
      "Epoch 127/150\n",
      "782/782 - 7s - loss: 1.6037 - accuracy: 0.4499\n",
      "Epoch 128/150\n",
      "782/782 - 7s - loss: 1.5861 - accuracy: 0.4547\n",
      "Epoch 129/150\n",
      "782/782 - 7s - loss: 1.5901 - accuracy: 0.4545\n",
      "Epoch 130/150\n",
      "782/782 - 7s - loss: 1.5902 - accuracy: 0.4572\n",
      "Epoch 131/150\n",
      "782/782 - 7s - loss: 1.5933 - accuracy: 0.4528\n",
      "Epoch 132/150\n",
      "782/782 - 7s - loss: 1.5891 - accuracy: 0.4565\n",
      "Epoch 133/150\n",
      "782/782 - 7s - loss: 1.5936 - accuracy: 0.4534\n",
      "Epoch 134/150\n",
      "782/782 - 7s - loss: 1.5848 - accuracy: 0.4583\n",
      "Epoch 135/150\n",
      "782/782 - 7s - loss: 1.5843 - accuracy: 0.4586\n",
      "Epoch 136/150\n",
      "782/782 - 7s - loss: 1.5876 - accuracy: 0.4578\n",
      "Epoch 137/150\n",
      "782/782 - 7s - loss: 1.5888 - accuracy: 0.4562\n",
      "Epoch 138/150\n",
      "782/782 - 7s - loss: 1.5877 - accuracy: 0.4574\n",
      "Epoch 139/150\n",
      "782/782 - 7s - loss: 1.5875 - accuracy: 0.4574\n",
      "Epoch 140/150\n",
      "782/782 - 7s - loss: 1.5912 - accuracy: 0.4566\n",
      "Epoch 141/150\n",
      "782/782 - 7s - loss: 1.5888 - accuracy: 0.4565\n",
      "Epoch 142/150\n",
      "782/782 - 7s - loss: 1.5891 - accuracy: 0.4551\n",
      "Epoch 143/150\n",
      "782/782 - 7s - loss: 1.5814 - accuracy: 0.4586\n",
      "Epoch 144/150\n",
      "782/782 - 7s - loss: 1.5819 - accuracy: 0.4612\n",
      "Epoch 145/150\n",
      "782/782 - 7s - loss: 1.5861 - accuracy: 0.4606\n",
      "Epoch 146/150\n",
      "782/782 - 7s - loss: 1.5885 - accuracy: 0.4584\n",
      "Epoch 147/150\n",
      "782/782 - 7s - loss: 1.5952 - accuracy: 0.4573\n",
      "Epoch 148/150\n",
      "782/782 - 7s - loss: 1.5819 - accuracy: 0.4627\n",
      "Epoch 149/150\n",
      "782/782 - 7s - loss: 1.5894 - accuracy: 0.4599\n",
      "Epoch 150/150\n",
      "782/782 - 7s - loss: 1.5769 - accuracy: 0.4611\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3937 - accuracy: 0.6042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3936501741409302, 0.604200005531311]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = my_model()\r\n",
    "\r\n",
    "model.compile(\r\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\r\n",
    "    metrics=['accuracy']\r\n",
    ")\r\n",
    "\r\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=150, verbose=2)\r\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52035e4d146f99c150422bfac8e07f32a30b89a60d9dd60756d600c4b026426f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}